# voice_ai_backend/services/llm_service.py
import json
import httpx
import re
from typing import AsyncGenerator
from core.interfaces import ILLMService


class CustomLLMService(ILLMService):
    def __init__(self, api_url: str):
        self.api_url = api_url

    def _clean_response(self, text: str) -> str:
        """
        AI Ã§Ä±ktÄ±sÄ±ndan <think>...</think> bloklarÄ±nÄ± ve gereksiz boÅŸluklarÄ± temizler.
        """
        # <think> ve </think> arasÄ±ndaki her ÅŸeyi (satÄ±r sonlarÄ± dahil) sil
        clean_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

        # OlasÄ± diÄŸer sistem taglerini de temizleyebilirsiniz (opsiyonel)
        # clean_text = re.sub(r'<\|.*?\|>', '', clean_text)

        return clean_text.strip()

    async def generate_stream(self, system_prompt: str, user_query: str, context: str = "") -> AsyncGenerator[
        str, None]:
        """
        Mihenk-14B (FastAPI) entegrasyonu.
        Gelen cevabÄ± temizler ve simÃ¼le edilmiÅŸ stream olarak dÃ¶ner.
        """

        full_prompt = f"""
        [TALÄ°MAT]: {system_prompt}

        [BAÄLAM BÄ°LGÄ°SÄ°]:
        {context}

        [KULLANICI SORUSU]:
        {user_query}
        """

        payload = {
            "prompt": full_prompt
        }

        print(f"ğŸ“¡ [LLM] Ä°stek gÃ¶nderiliyor: {self.api_url}")

        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(self.api_url, json=payload)

                if response.status_code != 200:
                    err = f"âŒ [LLM Hata] Status: {response.status_code} - {response.text}"
                    print(err)
                    yield err
                    return

                # JSON cevabÄ±nÄ± al
                data = response.json()
                raw_text = data.get("response", "")

                # --- TEMÄ°ZLÄ°K AÅAMASI ---
                final_text = self._clean_response(raw_text)

                print(f"âœ… [LLM] TemizlenmiÅŸ Cevap: {final_text[:50]}...")

                # EÄŸer temizlik sonrasÄ± metin boÅŸsa uyarÄ± ver
                if not final_text:
                    yield "ÃœzgÃ¼nÃ¼m, geÃ§erli bir cevap oluÅŸturulamadÄ±."
                    return

                # Kelime kelime simÃ¼lasyon (TTS ve Frontend iÃ§in)
                words = final_text.split(" ")
                for word in words:
                    yield word + " "

            except Exception as e:
                print(f"\nâŒ [LLM BaÄŸlantÄ± HatasÄ±]: {e}")
                yield f"BaÄŸlantÄ± HatasÄ±: {str(e)}"